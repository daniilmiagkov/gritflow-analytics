import os
import cv2
import tifffile
import numpy as np
import itertools
import sys
from pathlib import Path
from multiprocessing import Pool, cpu_count, get_context
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Optional, Dict, Any, List

# ÐŸÑƒÑ‚ÑŒ Ðº ÐºÐ¾Ñ€Ð½ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

from processing.analyzer import analyze_frame
from processing.color_config import ColorConfig
from processing.visual_config import VisualizationConfig
from config import OUTPUT_DIR, FRAME_NUMBER


# --- Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ multiprocessing ---
global_color: Optional[np.ndarray] = None
global_depth: Optional[np.ndarray] = None


def init_worker_shared_data(frame_number: int):
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ð±Ñ‰Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ."""
    global global_color, global_depth

    color_path = os.path.join(OUTPUT_DIR, f"frame_{frame_number}_color.png")
    depth_path = os.path.join(OUTPUT_DIR, f"frame_{frame_number}_depth.tiff")

    color = cv2.imread(color_path, cv2.IMREAD_COLOR)
    depth = tifffile.imread(depth_path)

    if color is None:
        raise FileNotFoundError(f"âŒ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ„Ð°Ð¹Ð» Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {color_path}")
    if depth is None or not isinstance(depth, np.ndarray):
        raise FileNotFoundError(f"âŒ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ„Ð°Ð¹Ð» Ð³Ð»ÑƒÐ±Ð¸Ð½Ñ‹ Ð¸Ð»Ð¸ Ð¾Ð½ Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚ÐµÐ½: {depth_path}")

    global_color = color
    global_depth = depth


def worker(args):
    override, base_cfg_dict, frame_number = args
    global global_color

    try:
        cfg = ColorConfig(**base_cfg_dict)
        for k, v in override.items():
            setattr(cfg, k, v)

        vis_cfg = VisualizationConfig(show_plots=False)

        # ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        c_res, c_diams, _ = analyze_frame(global_color, cfg, vis_cfg)

        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
        MIN_COUNT = 150
        BIG_THRESHOLD = 40.0
        SMALL_THRESHOLD = 15.0  # ÑƒÑÐ»Ð¾Ð²Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ð´Ð»Ñ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ñ…

        total_count = len(c_diams)
        big_count = sum(1 for d in c_diams if d > BIG_THRESHOLD)
        small_count = sum(1 for d in c_diams if d < SMALL_THRESHOLD)
        mean_diameter = float(np.mean(c_diams)) if c_diams else 0.0
        median_diameter = float(np.median(c_diams)) if c_diams else 0.0

        # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹
        if total_count < MIN_COUNT or not (2 <= big_count <= 3):
            return None

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ
        parts = [f"{k[:2]}-{str(v).replace(' ', '')}" for k, v in override.items()]
        name = f"color_{'_'.join(parts)}_frame-{frame_number}.png"
        save_path = os.path.join(OUTPUT_DIR, name)
        cv2.imwrite(save_path, c_res)

        return {
            "path": save_path,
            "params": override,
            "total_count": total_count,
            "big_count": big_count,
            "small_count": small_count,
            "mean_diameter": mean_diameter,
            "median_diameter": median_diameter,
        }

    except Exception as e:
        print(f"[PID {os.getpid()}] âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ {override}: {e}")
        return None



def analyze_results(results: List[Dict[str, Any]], output_dir: str):
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¸ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸."""

    print("\n=== ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² ===")
    param_stats = defaultdict(lambda: defaultdict(int))

    for r in results:
        for k, v in r["params"].items():
            param_stats[k][v] += 1

    print("\nÐ§Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² (Ð² ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑÑ…):")
    for param, val_counts in param_stats.items():
        print(f"\n[{param}]")
        for val, count in sorted(val_counts.items(), key=lambda x: -x[1]):
            print(f"  {val}: {count} Ñ€Ð°Ð·")

    # ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²
    print("\nðŸ“ˆ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² Ð¿Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼...")
    num_params = len(param_stats)
    fig, axes = plt.subplots(nrows=num_params, ncols=1, figsize=(10, 5 * num_params))

    if num_params == 1:
        axes = [axes]

    for ax, (param, val_counts) in zip(axes, param_stats.items()):
        items = sorted(val_counts.items(), key=lambda x: str(x[0]))
        labels = [str(k) for k, _ in items]
        values = [v for _, v in items]

        sns.barplot(x=labels, y=values, ax=ax)
        ax.set_title(f"Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°: {param}")
        ax.set_ylabel("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹")
        ax.set_xlabel(param)
        ax.grid(True)

    plt.tight_layout()
    plot_path = os.path.join(output_dir, "param_distribution.png")
    plt.savefig(plot_path)
    print(f"ðŸ“Š ÐŸÐ»Ð¾Ñ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: {plot_path}")


def main():
    base_cfg = ColorConfig()
    base_cfg_dict = vars(base_cfg)

    param_tests = {
        "median_blur_size":           [3, 5, 7],
        "adaptive_thresh":            [True],
        "adaptive_block_size":        [5, 7, 9, 11, 13, 15],
        "adaptive_C":                 [-2, 0, 2, 3],
        "use_otsu":                   [False],
        "binary_thresh":              [0],
        "morph_kernel_shape":         ["ellipse"],
        "morph_kernel_size":          [2, 3, 5],
        "morph_iterations":           [1, 2, 3],
        "min_particle_size":          [10],
        "max_particle_size":          [150],
        "distance_transform_mask":    [3, 5],
        "foreground_threshold_ratio": [0.1, 0.16, 0.2],
        "dilate_iterations":          [1],
    }

    keys = list(param_tests.keys())
    value_lists = [param_tests[k] for k in keys]

    tasks = [
        (dict(zip(keys, combo)), base_cfg_dict, FRAME_NUMBER)
        for combo in itertools.product(*value_lists)
    ]

    print(f"\n=== ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº {len(tasks)} Ð·Ð°Ð´Ð°Ñ‡ Ð½Ð° {cpu_count()} ÑÐ´Ñ€Ð°Ñ… ===\n")

    ctx = get_context("spawn")
    with ctx.Pool(cpu_count(), initializer=init_worker_shared_data, initargs=(FRAME_NUMBER,)) as pool:
        results = pool.map(worker, tasks)

    filtered = [r for r in results if r]

    print(f"\n=== âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹: {len(filtered)} ===")
    for r in filtered:
        print(f"âœ” {r['path']} â€” Ð²ÑÐµÐ³Ð¾: {r['total_count']}, Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ…: {r['big_count']}")
        # ÐœÐ¾Ð¶Ð½Ð¾ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³, ÐµÑÐ»Ð¸ Ð½Ð°Ð´Ð¾:
        cfg = ColorConfig(**{**vars(ColorConfig()), **r["params"]})
        print(cfg)
        print()

    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ ÑÑ‚Ñ€Ð¾Ð¸Ð¼ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸ Ð¿Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼
    analyze_results(filtered, OUTPUT_DIR)


if __name__ == "__main__":
    main()
