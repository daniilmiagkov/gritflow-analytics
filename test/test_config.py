import os
import cv2
import tifffile
import numpy as np
import itertools
import json
import sys
from pathlib import Path
from multiprocessing import Pool, cpu_count, get_context
from collections import defaultdict
import pandas as pd
from typing import Tuple, Optional, Dict, Any, List

# ÐŸÑƒÑ‚ÑŒ Ðº ÐºÐ¾Ñ€Ð½ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

from processing.analyzer import analyze_frame
from processing.depth_config import DepthConfig
from processing.color_config import ColorConfig
from processing.visual_config import VisualizationConfig
from config import OUTPUT_DIR, FRAME_NUMBER


import matplotlib.pyplot as plt
import seaborn as sns

# --- Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ multiprocessing (Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ) ---
global_color: Optional[np.ndarray] = None
global_depth: Optional[np.ndarray] = None


def init_worker_shared_data(frame_number: int):
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ð±Ñ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ."""
    global global_color, global_depth

    color_path = os.path.join(OUTPUT_DIR, f"frame_{frame_number}_color.png")
    depth_path = os.path.join(OUTPUT_DIR, f"frame_{frame_number}_depth.tiff")

    color = cv2.imread(color_path, cv2.IMREAD_COLOR)
    depth = tifffile.imread(depth_path)

    if color is None:
        raise FileNotFoundError(f"âŒ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ„Ð°Ð¹Ð» Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {color_path}")
    if depth is None or not isinstance(depth, np.ndarray):
        raise FileNotFoundError(f"âŒ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ„Ð°Ð¹Ð» Ð³Ð»ÑƒÐ±Ð¸Ð½Ñ‹ Ð¸Ð»Ð¸ Ð¾Ð½ Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚ÐµÐ½: {depth_path}")

    global_color = color
    global_depth = depth


def worker(args):
    override, base_cfg_dict, frame_number = args
    global global_color

    try:
        cfg = ColorConfig(**base_cfg_dict)
        for k, v in override.items():
            setattr(cfg, k, v)

        vis_cfg = VisualizationConfig(show_plots=False)

        c_res, c_diams, _ = analyze_frame(global_color, cfg, vis_cfg)

        MIN_COUNT = 150
        BIG_THRESHOLD = 40.0
        total_count = len(c_diams)
        big_count = sum(1 for d in c_diams if d > BIG_THRESHOLD)

        if total_count < MIN_COUNT or not (2 <= big_count <= 3):
            return None

        parts = [f"{k[:2]}-{str(v).replace(' ', '')}" for k, v in override.items()]
        name = f"color_{'_'.join(parts)}_frame-{frame_number}.png"
        save_path = os.path.join(OUTPUT_DIR, name)
        cv2.imwrite(save_path, c_res)

        return {
            "path": save_path,
            "params": override,
            "total_count": total_count,
            "big_count": big_count,
        }

    except Exception as e:
        print(f"[PID {os.getpid()}] âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ {override}: {e}")
        return None
    
def analyze_results(results: List[Dict[str, Any]], output_csv_path: str = "param_analysis.csv"):
    print("\n=== ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² ===")
    param_stats = defaultdict(lambda: defaultdict(int))

    for r in results:
        for k, v in r["params"].items():
            param_stats[k][v] += 1

    # --- Ð’Ñ‹Ð²Ð¾Ð´ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼ ---
    print("\nÐ§Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² (Ð² ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑÑ…):")
    for param, val_counts in param_stats.items():
        print(f"\n[{param}]")
        for val, count in sorted(val_counts.items(), key=lambda x: -x[1]):
            print(f"  {val}: {count} Ñ€Ð°Ð·")

    # --- ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² ---
    print("\nðŸ“ˆ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² Ð¿Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼...")
    num_params = len(param_stats)
    fig, axes = plt.subplots(nrows=num_params, ncols=1, figsize=(10, 5 * num_params))

    if num_params == 1:
        axes = [axes]  # Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð°

    for ax, (param, val_counts) in zip(axes, param_stats.items()):
        items = sorted(val_counts.items(), key=lambda x: x[0])
        labels = [str(k) for k, _ in items]
        values = [v for _, v in items]

        sns.barplot(x=labels, y=values, ax=ax)
        ax.set_title(f"Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°: {param}")
        ax.set_ylabel("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹")
        ax.set_xlabel(param)
        ax.grid(True)

    plt.tight_layout()
    plot_path = os.path.join(OUTPUT_DIR, "param_distribution.png")
    plt.savefig(plot_path)
    print(f"ðŸ“Š ÐŸÐ»Ð¾Ñ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: {plot_path}")

    # # --- CSV ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ---
    # df = pd.DataFrame([
    #     {**r["params"], "total_count": r["total_count"], "big_count": r["big_count"]}
    #     for r in results
    # ])
    # csv_path = os.path.join(OUTPUT_DIR, output_csv_path)
    # df.to_csv(csv_path, index=False)
    # print(f"\nðŸ“ CSV ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: {csv_path}")

    # # --- Ð’Ñ‹Ð²Ð¾Ð´ ÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹ Ð² ÑÑ‚Ð¸Ð»Ðµ ColorConfig ---
    # print("\n=== âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ ===")
    # for r in results:
    #     cfg = ColorConfig(**{**vars(ColorConfig()), **r["params"]})  # Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð´ÐµÑ„Ð¾Ð»Ñ‚
    #     print(f"\n{cfg}")
    #     print(f"  ðŸ”¸ total_count = {r['total_count']}, big_count = {r['big_count']}")



def main():
    base_cfg = ColorConfig()
    base_cfg_dict = vars(base_cfg)

    # param_tests = {
    #     "median_blur_size":           [1, 3],
    #     "adaptive_thresh":            [True],
    #     "adaptive_block_size": [5, 7, 9],
    #     "adaptive_C": [-3, -2, -1, 0, 1, 2, 3, 4, 5],
    #     "use_otsu":                   [True],
    #     "binary_thresh":              [0],
    #     "morph_kernel_shape":         ["rect", "ellipse", "cross"],
    #     "morph_kernel_size":          [1, 2, 3, 4, 5, 7, 11],
    #     "morph_iterations":           [0, 1, 2, 3, 4],
    #     "min_particle_size":          [10],
    #     "max_particle_size":          [200],
    #     "distance_transform_mask":    [0, 3, 5],
    #     "foreground_threshold_ratio": [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7],
    #     "dilate_iterations":          [0, 1, 2, 3],
    # }

    param_tests = {
        # === ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ===
        "median_blur_size":           [3, 5],  # Ð´Ð¾Ð±Ð°Ð²Ð¸Ð¼ 5 â€” Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ð¿Ð¾Ð¼Ð¾Ð¶ÐµÑ‚ Ð»Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐµÐµ ÑÐ³Ð»Ð°Ð¶Ð¸Ð²Ð°Ð½Ð¸Ðµ

        # === ÐŸÐ¾Ñ€Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ ===
        "adaptive_thresh":            [True],  # Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³
        "adaptive_block_size":        [7, 9, 11, 13, 15],  # Ñ€Ð°ÑÑˆÐ¸Ñ€ÑÐµÐ¼ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ Ð²Ð²ÐµÑ€Ñ… Ð´Ð»Ñ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ñ… Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²
        "adaptive_C":                 [-2, 0, 2, 3],  # Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÑ…
        "use_otsu":                   [False],  # Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼, Ñ‚Ð°Ðº ÐºÐ°Ðº Ñ adaptive Ð½Ðµ Ð½ÑƒÐ¶ÐµÐ½
        "binary_thresh":              [0],  # Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ adaptive_thresh=False (Ð° Ñ‚ÑƒÑ‚ â€” Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ)

        # === ÐœÐ¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ===
        "morph_kernel_shape":         ["rect", "ellipse"],  # Ð¾ÑÑ‚Ð°Ð²Ð¸Ð¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ñ‹
        "morph_kernel_size":          [2, 3, 5],  # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ðµ â€” Ð¸ÑÐºÐ°Ð¶Ð°ÑŽÑ‚ Ð¼ÐµÐ»ÐºÐ¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹
        "morph_iterations":           [1, 2, 3],  # Ð´Ð°Ñ‘Ñ‚ Ð²Ñ‹Ð±Ð¾Ñ€ Ð´Ð»Ñ ÑƒÑÐ¸Ð»ÐµÐ½Ð¸Ñ Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð¸ Ñ€Ð°Ð·Ñ€Ñ‹Ð²Ð° ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð²

        # === Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÑƒÑ€Ð¾Ð² ===
        "min_particle_size":          [5],  # Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸ Ð¼ÐµÐ»ÐºÐ¸Ðµ, Ð¸ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ðµ
        "max_particle_size":          [150],  # Ñ€Ð°ÑÑˆÐ¸Ñ€Ð¸Ð¼ Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð¾Ñ‡ÐµÐ½ÑŒ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ñ… Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²

        # === Ð”Ð¾Ð¿. ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ (distance transform) ===
        "distance_transform_mask":    [3, 5],  # Ð¾ÑÑ‚Ð°Ð²Ð¸Ð¼ Ð²ÑÐµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹
        "foreground_threshold_ratio": [0.1, 0.16, 0.2],  # Ð´Ð¾Ð±Ð°Ð²Ð¸Ð¼ 0.16 Ð¸Ð· Ñ‚Ð²Ð¾ÐµÐ¹ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
        "dilate_iterations":          [1],  # ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ¸Ð»Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐ»Ð¸ÑÑŒ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹
    }



    # param_tests = {
    #     "median_blur_size":           [1, 3, 5],
    #     "adaptive_thresh":            [True],
    #     "binary_thresh":              [0],
    #     "morph_kernel_size":          [1, 2, ],
    #     "morph_iterations":           [1, 2],
    #     "min_particle_size":          [2, 3],
    #     "max_particle_size":          [200],
    #     "distance_transform_mask":    [1, 2, ],
    #     "foreground_threshold_ratio": [0.01, ],
    #     "dilate_iterations":          [1, 2, 3],
    # }


    keys = list(param_tests.keys())
    value_lists = [param_tests[k] for k in keys]
    tasks = [
        (dict(zip(keys, combo)), base_cfg_dict, FRAME_NUMBER)
        for combo in itertools.product(*value_lists)
    ]

    print(f"\n=== ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº {len(tasks)} Ð·Ð°Ð´Ð°Ñ‡ Ð½Ð° {cpu_count()} ÑÐ´Ñ€Ð°Ñ… ===\n")

    ctx = get_context("spawn")  # ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ Ð²Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ Windows
    with ctx.Pool(cpu_count(), initializer=init_worker_shared_data, initargs=(FRAME_NUMBER,)) as pool:
        results = pool.map(worker, tasks)

    # ÐžÑ‚Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ None
    filtered = [r for r in results if r]
    print(f"\n=== âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹: {len(filtered)} ===")
    for r in filtered:
        print(f"âœ” {r['path']} â€” Ð²ÑÐµÐ³Ð¾: {r['total_count']}, Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ…: {r['big_count']}")
        cfg = ColorConfig(**{**vars(ColorConfig()), **r["params"]})
        print(f"{cfg}\n")


    analyze_results(filtered)


if __name__ == "__main__":
    main()
